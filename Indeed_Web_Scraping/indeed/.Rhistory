test$CATALOG_PRICE
test['CATALOG_PRICE']  <- (cplte$CATALOG_PRICE/100000*cplte$CATALOG_PRICE/10000)
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- sqrt(cplte$CATALOG_PRICE/100000)
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- cplte$CATALOG_PRICE/100000
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- sqrt(cplte$CATALOG_PRICE)/10000
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- cplte$CATALOG_PRICE/100000
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- (cplte$CATALOG_PRICE/100000)^2
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- (cplte$CATALOG_PRICE/100000)^(3/4)
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- log(cplte$CATALOG_PRICE/100000)
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- cplte$CATALOG_PRICE/100000
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- cplte$CATALOG_PRICE/10000
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- cplte$CATALOG_PRICE/10000000
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- cplte$CATALOG_PRICE/1000
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- cplte$CATALOG_PRICE/10000
hist(test$CATALOG_PRICE)
test['CATALOG_PRICE']  <- cplte$CATALOG_PRICE/100000
hist(test$CATALOG_PRICE)
uchar['CATALOG_PRICE'] <- 1
test['CATALOG_PRICE']  <- cplte$CATALOG_PRICE/100000
# --------- Weight Matrix: -----------
# GENRE_NAME(13), DISCOUNT_PRICE(1), DISPPERIOD(1), large_area_name(9),
# small_area_name(55), VALIDPERIOD(2), USABLE_DATE_sum(1), ken_name(47), PRICE_RATE(1)
# ------- for men ----------
# genre: Gift card 2, Food 3, Other coupon 4, Hotel and Japanese hotel 8, Leisure 10
genre_m <- c(1.8,rep(2,3),1.8,1.8,1.8,rep(2,1),1.8,rep(2,1),1.8,1.8,1.8)
Wm <- diag(c(genre_m, 1.25, 1.25, rep(2.5,9), rep(4.5,55),
rep(.625,2), rep(.35,1), rep(.25,47), rep(-.01,1), rep(-.01,1)))
# ----------- for women ----------
# genre: Spa 1, Nail and eye salon 5, Beauty 6, Hair salon 7, Relaxation 9, Health and medical 12, Lesson 11
genre_f <- c(2.1,rep(1.65,3),rep(2.1,3),rep(1.65,1),2.1,rep(1.65),rep(2.1,2),1.65)
Wf <- diag(c(genre_f, 0.75, 1.50, rep(2.5,9), rep(4.5,55),
rep(.625,2), rep(.25,1), rep(.25,47), rep(-.01,1), rep(-.01,1)))
# ----------- calculation of cosine similairties of users and coupons -------------
#calculation of cosine similarities of users and coupons
score = as.matrix(uchar[,2:ncol(uchar)]) %*% Wm %*% t(as.matrix(test[,2:ncol(test)]))
score[ulist$SEX_ID=='f',] = as.matrix(uchar[ulist$SEX_ID=='f',2:ncol(uchar)]) %*% Wf %*% t(as.matrix(test[,2:ncol(test)]))
# save(file=paste0(dir,'score_007704.Rdata'),score)
####################
#colleting results #
####################
#order the list of coupons according to similairties and take only first 10 coupons
uchar$PURCHASED_COUPONS <- do.call(rbind, lapply(1:nrow(uchar),FUN=function(i){
purchased_cp <- paste(test$COUPON_ID_hash[order(score[i,], decreasing = TRUE)][1:10],collapse=" ")
return(purchased_cp)
}))
#make submission
submission <- uchar[,c("USER_ID_hash","PURCHASED_COUPONS")]
submission$PURCHASED_COUPONS[rowSums(score)==0] <- ""
write.csv(submission, file=paste0(dir,"/submit.csv"), row.names=FALSE)
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
View(ulist)
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_18.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
distance_test
View(test)
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
load(file <- paste0(dir,'/distance_test.Rdata'))
distance_test <- 1 / distance
remove(distance)
distance_test
load(file <- paste0(dir,'/distance_test.Rdata'))
distance_test <- distance / 100
distance_test
load(file <- paste0(dir,'/distance_test.Rdata'))
hist(distance)
load(file <- paste0(dir,'/distance_test.Rdata'))
distance_test <- 1 / (distance + 1)
hist(distance_test)
load(file <- paste0(dir,'/distance_test.Rdata'))
View(distance)
View(distance)
load(file <- paste0(dir,'/distance_test.Rdata'))
distance_test <- 1 / (distance + 1)
remove(distance)
distance_weight <- .05 * rep(1,13)
for (genre in 1:13) {
# which coupons are in this genre
distance_test[,cplte[,'GENRE_NAME'] == levels(cpltr[,'GENRE_NAME'])[genre]] <- distance_weight[genre] * distance_test[,cplte[,'GENRE_NAME'] == levels(cpltr[,'GENRE_NAME'])[genre]]
}
distance_test
score <- score + distance_test
View(score)
####################
#colleting results #
####################
#order the list of coupons according to similairties and take only first 10 coupons
uchar$PURCHASED_COUPONS <- do.call(rbind, lapply(1:nrow(uchar),FUN=function(i){
purchased_cp <- paste(test$COUPON_ID_hash[order(score[i,], decreasing = TRUE)][1:10],collapse=" ")
return(purchased_cp)
}))
#make submission
submission <- uchar[,c("USER_ID_hash","PURCHASED_COUPONS")]
submission$PURCHASED_COUPONS[rowSums(score)==0] <- ""
write.csv(submission, file=paste0(dir,"/submit.csv"), row.names=FALSE)
distance_test
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/email_disclosure/country_map.R')
install.packages("rworldmap")
source('~/Dropbox/data science/kaggle/email_disclosure/country_map.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19_008597.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19_008597.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19_008597.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19_008597.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_19_008597.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_20.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_20.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_20.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_20.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_20.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_20.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_20.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_20.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_20.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_20_8662.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_20_8662.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_23.R')
length(capsule_m)
genre_m   <- c(1.8,rep(2,3),1.8,1.8,1.8,rep(2,1),1.8,rep(2,1),1.8,1.8,1.8)
# capsule: イベント 2(3/2.5), ギフトカード 4(1200:800), グルメ 5(2200:1500), ゲストハウス 6(3.5:1)
# capsule: その他 7(2300:1800), ペンション 12(35:15), ホテル 13(800:560), レジャー 15(700:500)
# capsule: 宅配 20(4000:4000), 旅館 21(400:250), 民宿 22(20:10)
capsule_m <- c(rep(.02,5),.1,rep(.02,5),.1,rep(.02,9),.1,rep(.02,3))
Wm <- diag(c(genre_m, 1.25, 1.25, rep(5.5,9), rep(4.5,55)#over
,.425, 1.5,rep(.35,1), rep(1.0,47), rep(-.01,1), capsule_m, rep(.03,1)))
# ----------- for women ----------
# genre: Spa 1, Nail and eye salon 5, Beauty 6, Hair salon 7, Relaxation 9, Health and medical 12, Lesson 11
genre_f <- c(2.1,rep(1.65,3),rep(2.1,3),rep(1.65,1),2.1,rep(1.65),rep(2.1,2),1.65)
# capsule: サービス 1 (60:40), エステ 3 (220:40), ネイル・アイ 8(220:10), ビューティ 9(.2:0)
# capsule: ビューティー 10(15:2), ヘアサロン 11(430:100), リラクゼーション 14(250:125)
# capsule: レッスン 16(300:125), ロッジ17(3:2), 健康・医療 18(22:12), 公共の宿 19(1:.8)
# capsule: 宅配 20(4000:4000), 貸別荘 23(5:3), 通信講座 24(1.2:.8), 通学レッスン 25(6:1)
capsule_f <- c(rep(.02,2),.1,rep(.02,4),.1,.02,.1,.1,rep(.02,13),.1)
Wf <- diag(c(genre_f, 0.75, 1.65, rep(7,9), rep(4.5,55)#over
,.425, 1.5,rep(.25,1), rep(1.5,47), rep(-.01,1), capsule_f, rep(.03,1)))
# ----------- calculation of cosine similairties of users and coupons -------------
#calculation of cosine similarities of users and coupons
score = as.matrix(uchar[,2:ncol(uchar)]) %*% Wm %*% t(as.matrix(test[,2:ncol(test)]))
score[ulist$SEX_ID=='f',] = as.matrix(uchar[ulist$SEX_ID=='f',2:ncol(uchar)]) %*% Wf %*% t(as.matrix(test[,2:ncol(test)]))
################
# add distance #
################
# -------------- add distance ---------------
load(file <- paste0(dir,'/distance_test.Rdata'))
distance_test <- 1 / (distance + 1)
remove(distance)
distance_weight <- .1 * c(rep(1,2), -1.5, -1.5, rep(1,1), rep(1,6), 1, -2)
for (genre in 1:13) {
# which coupons are in this genre
distance_test[,cplte[,'GENRE_NAME'] == levels(cpltr[,'GENRE_NAME'])[genre]] <- distance_weight[genre] * distance_test[,cplte[,'GENRE_NAME'] == levels(cpltr[,'GENRE_NAME'])[genre]]
}
score <- score + distance_test
# #####################
# #load orignial uchar#
# #####################
# load(file = paste0(dir,'/uchar.Rdata'))
# uchar['CATALOG_PRICE'] <- 1
# score_o = as.matrix(uchar[,2:ncol(uchar)]) %*% Wm %*% t(as.matrix(test[,2:ncol(test)]))
# score_o[ulist$SEX_ID=='f',] = as.matrix(uchar[ulist$SEX_ID=='f',2:ncol(uchar)]) %*% Wf %*% t(as.matrix(test[,2:ncol(test)]))
# score_o <- score_o + distance_test
#
# # -------- find coupon with delivery genre --------
# coupon_delivery <- cplte[,'GENRE_NAME'] == '宅配'
# score <- t(apply(score,1,FUN =scale))
# score_o <- t(apply(score_o,1,FUN=scale))
# score <- .8*score + .2*score_o
####################
#colleting results #
####################
#order the list of coupons according to similairties and take only first 10 coupons
uchar$PURCHASED_COUPONS <- do.call(rbind, lapply(1:nrow(uchar),FUN=function(i){
purchased_cp <- paste(test$COUPON_ID_hash[order(score[i,], decreasing = TRUE)][1:10],collapse=" ")
return(purchased_cp)
}))
#make submission
submission <- uchar[,c("USER_ID_hash","PURCHASED_COUPONS")]
submission$PURCHASED_COUPONS[rowSums(score)==0] <- ""
write.csv(submission, file=paste0(dir,"/submit.csv"), row.names=FALSE)
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_23.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_23.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
source('~/Dropbox/data science/kaggle/coupon purchase prediction/our_try_26.R')
1:5
examinee_all=matrix(3,2,3)
examinee_all
examinee_all=2
response_matrix=examinee_all
examinee_all=1:2
response_matrix[,item] != 9
response_matrix[,2] != 9
response_matrix[,2]
response_matrix
response_matrix=matrix(1,3,2)
response_matrix
response_matrix=matrix(1,2,3)
response_matrix
examinee_all
response_matrix[,2]
response_matrix[,2]!=9
examinee_all[response_matrix[,2]!=9]
?optimize
?optim
?outer
F=function(a,b){}
F=function(a,b){return(a+b)}
F(1,2)
a=seq(0, 5, by=0.1)
b=seq(0.1, 5, by =0.1)
outer(a, b, FUN=F)
a
b
a=1:3
b=4:6
outer(a, b, FUN=F)
c=outer(a, b, FUN=F)
which(max(c))
which(c==max(c))
which(c == max(c), arr.ind = TRUE)
F=function(a,b,c){return(a+b+c)}
a
b
c=7:8
mm=outer(a, b, c,FUN=F)
c=7:9
mm=outer(a, b, c,FUN=F)
mm
a
b
c
?optimise
?optimize
?optim
?optimHess
?optim
fr <- function(x) {   ## Rosenbrock Banana function
x1 <- x[1]
x2 <- x[2]
100 * (x2 - x1 * x1)^2 + (1 - x1)^2
}
optim(c(-1.2,1), fr)
x1=-10:10
x2=x1
y=100 * (x2 - x1 * x1)^2 + (1 - x1)^2
outer(x1,x2,fr)
f=function(x1,x2){100 * (x2 - x1 * x1)^2 + (1 - x1)^2}
outer(x1,x2,fr)
outer(x1,x2,f)
f(1.000260 ,1.000506)
f(1.000260 ,2)
f(2 ,2)
f(0 ,0)
f(0.5 ,0.5)
m <- matrix(c(1:10, 11:20), nrow = 10, ncol = 2)
m
apply(m, 1, mean)
apply(m, 2, mean)
function(x){}
function(x){return x/2}
function(x){return(x/2)}
a=function(x){return(x/2)}
apply(m,1,a)
apply(m, 1:2, function(x) x/2)
source('~/xgboost/R-package/R/xgb.plot.tree.R')
# -------------------------initialize-------------------------------------
rm(list = ls())
# dev.off(dev.list()["RStudioGD"])
# ???????????????????
response <- "converted"
# ???????????????????
#libraries needed
require(dplyr)
require(rpart)
require(ggplot2)
require(randomForest)
require(xgboost)
require(DiagrammeR)
# ---------------------------- data preprocessing --------------------------------------------------
data = read.csv("conversion_data.csv")
names(data)[names(data) == response] <- "response"
head(data)
str(data)
data$new_user <- as.factor(data$new_user) # this a factor
name <- setdiff(name <- names(data), "response")
summary(data)
# ?????????????????
sort(unique(data$age), decreasing=TRUE)
data = subset(data, age<80)
# ????????????????
# ----------------------------- data visulization-------------------------------------------------------
# Check distribution of response
percent <- data.frame(response = c(1,0), percent=c(sum(data$response)/length(data$response), 1))
ggplot(percent) +
aes(x = response, y = percent) +
geom_bar(stat = "identity", fill = "pink") +
theme_bw() +
theme(text = element_text(size = 20)) +
xlab(response)
ggsave("response.pdf",path = paste(getwd(),"/figs",sep=""))
# Each variable by response
var_index <- 0
for (var in name) {
var_index <- var_index + 1
data_group <- data %>% group_by_(var=as.symbol(var)) %>%
summarise(conversion_rate = mean(response))
if (class(data[,var]) == "factor") {
ggplot(data_group, aes(x=var, y = conversion_rate)) +
geom_bar(aes(fill = var), stat = "identity") +
theme_bw() +
labs(x = var, y = paste(response, "percentage")) +
theme(text = element_text(size = 20)) +
theme(legend.position="none")
ggsave(paste("var",var_index,".pdf",sep=""),
path = paste(getwd(),"/figs",sep=""))
} else {
ggplot(data_group, aes(x=var, y = conversion_rate)) +
geom_line(aes(color = conversion_rate)) +
theme_bw() +
labs(x = var, y = paste(response, "percentage")) +
theme(text = element_text(size = 20)) +
theme(legend.position="none")
ggsave(paste("var",var_index,".pdf",sep=""),
path = paste(getwd(),"/figs",sep=""))
}
}
# Check interactions
var_index <- 0
for (i1 in 1:length(name)) {
if (i1 == length(name)) {break}
for (i2 in (i1+1):length(name)) {
var_index <- var_index + 1
var1 = names(data)[i1]
var2 = names(data)[i2]
if (class(data[,var1]) == "factor" && class(data[,var2]) == "factor") {
data_group = data %>% group_by_(var1=as.symbol(var1), var2=as.symbol(var2)) %>%
summarise(conversion_rate = mean(response))
} else if (class(data[,var1]) != "factor" && class(data[,var2]) != "factor") {
data$var_1 <- cut(data[,var1], 3)
data$var_2 <- cut(data[,var2], 3)
data_group <- data %>% group_by(var1=var_1, var2=var_2) %>%
summarise(conversion_rate=mean(response))
} else if (class(data[,var1]) == "factor") {
data$var_2 <- cut(data[,var2], 3)
var_2 <- "var_2"
data_group <- data %>% group_by_(var1=as.symbol(var1), var2=var_2) %>%
summarise(conversion_rate=mean(response))
} else {
data$var_1 <- cut(data[,var1], 3)
var_1 <- "var_1"
data_group <- data %>% group_by_(var1=as.symbol(var_1), var2=as.symbol(var2)) %>%
summarise(conversion_rate=mean(response))
}
ggplot(data_group, aes(x=var2, y = conversion_rate, color = var1, group =var1)) +
geom_point() +
geom_line() +
theme_bw() +
labs(x = var2, y = paste(response, "percentage")) +
scale_colour_discrete(name=var1) +
theme(text = element_text(size = 25),
legend.key = element_rect(fill=alpha("white",0)),
legend.position = c(0.2,.75))
ggsave(paste("inter",var_index,".pdf",sep=""),
path = paste(getwd(),"/figs",sep=""),
height = 8, width = 8)
data <- subset(data, select = c(name, "response"))
}
}
# -----------------------------model building-------------------------------------------------------
data$response = as.factor(data$response) # let's make the class a factor
# split traing and testing data
train_sample = sample(nrow(data), size = nrow(data)*0.66)
train_data = data[train_sample,]
test_data = data[-train_sample,]
source('~/Box Sync/data science/interview/Take_home/AB_test/ab_test.R')
library(maps)
library(openintro)
library(dplyr)
states <- read.csv("state.csv")
states[,'State'] <- tolower(abbr2state(states[,'State']))
states_map <- map_data("state")
setwd("~/Desktop/indeed/indeed")
library(ggplot2)
library(maps)
library(openintro)
library(dplyr)
states <- read.csv("state.csv")
states[,'State'] <- tolower(abbr2state(states[,'State']))
states_map <- map_data("state")
View(states_map)
View(states)
states[,'Percentage'] <- states[,'NumPostings'] / sum(states[,'NumPostings'])
states[,'Percentage'] <- 1 - states[,'NumPostings'] / sum(states[,'NumPostings'])
states[,'Percentage'] <- 1 - states[,'NumPostings'] / sum(states[,'NumPostings'])
states[,'Percentage'] <- states[,'NumPostings'] / sum(states[,'NumPostings'])
states[,'Percentage'] <- 1 - states[,'NumPostings'] / sum(states[,'NumPostings'])
states[,'Percentage'] <- scale(1 - states[,'NumPostings'] / sum(states[,'NumPostings']))
states[,'Percentage'] <- 1 - states[,'NumPostings'] / sum(states[,'NumPostings'])
states[,'Percentage'] <- max(states[,'NumPostings'] / sum(states[,'NumPostings'])) - states[,'NumPostings'] / sum(states[,'NumPostings'])
states[,'Percentage'] <- states[,'NumPostings'] / sum(states[,'NumPostings'])
states[,'Percentage'] <- (states[,'NumPostings'] - min(states[,'NumPostings']) /
(max(states[,'NumPostings']) - min(states[,'NumPostings']))
)
states[,'Percentage'] <- states[,'NumPostings'] - min(states[,'NumPostings']) /
(max(states[,'NumPostings']) - min(states[,'NumPostings']))
states[,'Percentage'] <- (states[,'NumPostings'] - min(states[,'NumPostings'])) /
(max(states[,'NumPostings']) - min(states[,'NumPostings']))
states[,'Percentage'] <- 1 -(states[,'NumPostings'] - min(states[,'NumPostings'])) /
(max(states[,'NumPostings']) - min(states[,'NumPostings']))
states[,'Percentage'] <- (states[,'NumPostings'] - min(states[,'NumPostings'])) /
(max(states[,'NumPostings']) - min(states[,'NumPostings']))
states[,'Percentage'] <- 1 - (states[,'NumPostings'] - min(states[,'NumPostings'])) /
(max(states[,'NumPostings']) - min(states[,'NumPostings']))
hist(states$Percentage)
hist(log(states$Percentage))
hist(log(states$NumPostings))
states[,'log'] <- log(states$NumPostings)
states$percent <- 1 - (states$percent-min(states$percent)) / (max(states$percent)-min(states$percent))
states$log <- log(states$NumPostings)
states$percent <- 1 - (states$percent-min(states$percent)) / (max(states$percent)-min(states$percent))
states$percent <- 1 - (states$log-min(states$log)) / (max(states$log)-min(states$log))
states <- read.csv("state.csv")
states[,'State'] <- tolower(abbr2state(states[,'State']))
states_map <- map_data("state")
states$log <- log(states$NumPostings)
states$percent <- 1 - (states$log-min(states$log)) / (max(states$log)-min(states$log))
state.abb('alabama')
library(openintro)
state.abb('alabama')
library(maps)
state.abb('alabama')
View(states)
View(states)
View(states)
getwd()
